{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import backtrader as bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_decision(data, strat, threshold, safety_threshold, short_long_threshold, safety):\n",
    "    \"\"\"\n",
    "    Take a stock data dictionary and a strategy with settings, calculate the strategy positions and add them to the\n",
    "    data dictionary. Return the updated data dictionary.\n",
    "    \"\"\"\n",
    "    #[data, strat, threshold, safety_threshold, short_long_threshold, safety] = args\n",
    "    \n",
    "    if strat=='SMA_MR':\n",
    "        if safety==True:\n",
    "            #SMA extension signal\n",
    "            data['extension_position'] = np.nan\n",
    "            data['extension_position'] = np.where((data['extension']<-threshold) & (data['extension']>-safety_threshold), 1, data['extension_position'])\n",
    "            data['extension_position'] = np.where(data['extension']>-0.01, 0, data['extension_position'])\n",
    "            data['extension_position'] = data['extension_position'].ffill().fillna(0)\n",
    "\n",
    "            #Short-Long SMA signal\n",
    "            data['short_long_position'] = np.nan\n",
    "            data['short_long_position'] = np.where(data['SMA_short_long']<1-short_long_threshold, 1, data['short_long_position']) #adjusted threshold to 0.95 to leave a hold band around 1\n",
    "            data['short_long_position'] = np.where(data['SMA_short_long']>1, 0, data['short_long_position'])\n",
    "            data['short_long_position'] = data['short_long_position'].ffill().fillna(0)\n",
    "            \n",
    "            #Add signal to check if the market is in a mean-reverting regime (Ehlers/Kalman filters)\n",
    "            \n",
    "            #Add signal to check market volatility (see https://decodingmarkets.com/mean-reversion-trading-strategy/ step 7)\n",
    "            \n",
    "            #Set the position to 1 if both signal positions are 1. Else, set the position to 0.\n",
    "            data['position'] = np.nan\n",
    "            data['position'] = data['extension_position']*data['short_long_position']\n",
    "        else:\n",
    "            #SMA extension signal\n",
    "            data['extension_position'] = np.nan\n",
    "            #If extension is below our threshold, buy. Else, hold\n",
    "            data['extension_position'] = np.where(data['extension']<-threshold, 1, data['extension_position'])\n",
    "            #If we the extension is within 0.01 of a neutral value, sell. Else, hold\n",
    "            data['extension_position'] = np.where(data['extension']>-threshold, 0, data['extension_position'])\n",
    "            data['extension_position'] = data['extension_position'].ffill().fillna(0)\n",
    "\n",
    "            #Short-Long SMA signal\n",
    "            data['short_long_position'] = np.nan\n",
    "            data['short_long_position'] = np.where(data['SMA_short_long']<1-short_long_threshold, 1, data['short_long_position'])\n",
    "            data['short_long_position'] = np.where(data['SMA_short_long']>1, 0, data['short_long_position'])\n",
    "            data['short_long_position'] = data['short_long_position'].ffill().fillna(0)\n",
    "\n",
    "            #Set the position to 1 if both signal positions are 1. Else, set the position to 0.\n",
    "            data['position'] = np.nan\n",
    "            data['position'] = data['extension_position']*data['short_long_position']\n",
    "    else:\n",
    "        print('Please enter a valid strategy name. Currently supported strategies: \"SMA_MR\"')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAMeanReversion_strat(strat_settings):\n",
    "    \"\"\"\n",
    "    Evaluate a stock using two versions of SMA mean reversion strategy and make a buy/hold/sell decision\n",
    "    \n",
    "    Inputs\n",
    "        ticker (str) - stock ticker\n",
    "        sma (int) - rolling average window size, in days\n",
    "        threshold (float) - mean reversion significance threshold, >0\n",
    "        current_position (int) - our current position for this stock \n",
    "            1 means we own the stock, 0 means we do not\n",
    "        safety (bool) - if True, activate safety latch\n",
    "        safety_threshold (float) - safety latch threshold, >0\n",
    "        short_term_sma (int) - window size for short sma\n",
    "        long_term_sma (int) - window size for long sma\n",
    "        short_long_threshold (float) - short_long ratio significance threshold\n",
    "        tp_threshold (float) - percentage of expected profit to set take-profit order at, 0<x<1\n",
    "        \n",
    "        Must have safety_threshold > threshold\n",
    "    Outputs\n",
    "        decision (dataframe) - contains stock ticker, current extension, and strategy decision\n",
    "        \n",
    "    ticker, sma, threshold, current_position, safety=False, safety_threshold=0.25, short_term_sma=30, long_term_sma=90, short_long_threshold=0.05, tp_thresh=0.7\n",
    "    \"\"\"\n",
    "    [ticker,sma,threshold,current_position,safety,safety_threshold,short_term_sma,long_term_sma,short_long_threshold,tp_threshold] = strat_settings\n",
    "    \n",
    "    strat = 'SMA_MR'\n",
    "    \n",
    "    #end_date = '2021-07-24'\n",
    "    end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.today() - timedelta(days=2*long_term_sma)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    #Can add a switch to use either yfinance or a different library. Only column we need is data['Close']\n",
    "    #Get yahooFinance historical data\n",
    "    yfObj = yf.Ticker(ticker)\n",
    "    data = yfObj.history(start=start_date, end=end_date)\n",
    "    \n",
    "    #Calculate SMA and extension at the end of each day\n",
    "    #current_price = yfObj.info['regularMarketPrice']\n",
    "    data['SMA'] = data['Close'].rolling(sma).mean()\n",
    "    data['extension'] = (data['Close'] - data['SMA']) / data['SMA']\n",
    "    data['SMA_short_long'] = data['Close'].rolling(short_term_sma).mean() / data['Close'].rolling(long_term_sma).mean()\n",
    "    \n",
    "    #Add signal to check if the market is in a mean-reverting regime (Ehlers/Kalman filters)    \n",
    "    #Add signal to check market volatility (see https://decodingmarkets.com/mean-reversion-trading-strategy/ step 7)\n",
    "    \n",
    "    #Calculate actual price and expected price based on average of SMA and extension\n",
    "    ap = data['Close'][-1:] #Might replace with the instantaneous current price from the yfObj\n",
    "    ext_ep = data['SMA'][-1:]\n",
    "    sma_ep = data['Close'].rolling(long_term_sma).mean()[-1:]\n",
    "    ep = (ext_ep + sma_ep)/2\n",
    "    \n",
    "    #Check the strategy criteria at the end of each day and adjust the position accordingly\n",
    "    data = strat_decision(data, strat, threshold, safety_threshold, short_long_threshold, safety)\n",
    "\n",
    "    #Create a combined criteria that requires both the extension and the short_long ratio to agree in order to make a move\n",
    "    \"\"\"\n",
    "    if (data['extension'][-1:].values<-threshold) & (data['SMA_short_long'][-1:].values<1-short_long_threshold) & (current_position == 0):\n",
    "        print('signal 1 current 0')\n",
    "        movement = 'Buy'\n",
    "        #take-profit threshold\n",
    "        tp_price = ap + tp_threshold*(ep-ap)\n",
    "    else:\n",
    "        print('signal 0 current 0')\n",
    "        movement = 'Hold'\n",
    "        tp_price = 0\n",
    "    #Could make this an OR statement to conservatively sell if either signal is triggered\n",
    "    if (data['extension'][-1:].values>-threshold) & (data['SMA_short_long'][-1:].values>1) & (current_position == 1):\n",
    "        print('signal 0 current 1')\n",
    "        movement = 'Sell'\n",
    "        tp_price = 0\n",
    "    else:\n",
    "        if movement != 'Buy':\n",
    "            print('signal 1 current 1')\n",
    "            movement = 'Hold'\n",
    "            tp_price = ap + tp_threshold*(ep-ap)\n",
    "    \"\"\"\n",
    "    if (current_position == 0):\n",
    "        if (data['extension'][-1:].values<-threshold) & (data['SMA_short_long'][-1:].values<1-short_long_threshold):\n",
    "            #print('signal 1 current 0')\n",
    "            movement = 'Buy'\n",
    "            #take-profit threshold\n",
    "            tp_price = ap + tp_threshold*(ep-ap)\n",
    "        else:\n",
    "            #print('signal 0 current 0')\n",
    "            movement = 'Hold'\n",
    "            tp_price = 0\n",
    "    elif (current_position == 1):\n",
    "        #Could make this an OR statement to conservatively sell if either signal is triggered\n",
    "        if (data['extension'][-1:].values>-threshold) & (data['SMA_short_long'][-1:].values>1):\n",
    "            #print('signal 0 current 1')\n",
    "            movement = 'Sell'\n",
    "            tp_price = 0\n",
    "        else:\n",
    "            #print('signal 1 current 1')\n",
    "            movement = 'Hold'\n",
    "            tp_price = ap + tp_threshold*(ep-ap)\n",
    "            \n",
    "    #could implement a take-profit order where we sell when the price reaches the expected price (or a few percent below expected)\n",
    "    \n",
    "    #Get the extension & decision for this stock today and store it in a df\n",
    "    decision_dict = {}\n",
    "    decision_dict['ticker'] = ticker\n",
    "    #decision_dict['live_price'] = yfObj.info['regularMarketPrice'] #comment out to improve speed\n",
    "    decision_dict['latest_close_price'] = data['Close'][-1:]\n",
    "    decision_dict['expected_price'] = ep\n",
    "    decision_dict['extension'] = data['extension'][-1:]\n",
    "    decision_dict['extension_position'] = data['extension_position'][-1:]\n",
    "    decision_dict['short_long ratio'] = data['SMA_short_long'][-1:]\n",
    "    decision_dict['short_long_position'] = data['short_long_position'][-1:]\n",
    "    decision_dict['movement'] = movement\n",
    "    decision_dict['take_profit_price'] = tp_price\n",
    "    decision_dict['position'] = data['position'][-1:]\n",
    "    decision = pd.DataFrame(decision_dict).round(3)\n",
    "    \n",
    "    return decision, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratBacktest(strat_settings):\n",
    "    \"\"\"\n",
    "    Perform a backtest of a specified strategy for a given ticker\n",
    "    \n",
    "    Inputs\n",
    "        ticker (str) - stock ticker\n",
    "        sma (int) - rolling average window size, in days\n",
    "        threshold (float) - mean reversion significance threshold\n",
    "        start_date (str)\n",
    "        end_date (str)\n",
    "    Outputs\n",
    "        data (dataframe) - contains strategy returns and statistics data\n",
    "    \"\"\"\n",
    "    [ticker, strat, sma, threshold, safety, safety_threshold, short_term_sma, long_term_sma, short_long_threshold, start_date,end_date] = strat_settings\n",
    "    \n",
    "    #Can add a switch to use either yfinance or a different library. Only column we need is data['Close']\n",
    "    #Get yahooFinance historical data\n",
    "    yfObj = yf.Ticker(ticker)\n",
    "    warmup_date = (datetime.strptime(start_date, '%Y-%m-%d') - timedelta(days=2*long_term_sma)).strftime('%Y-%m-%d')\n",
    "    data = yfObj.history(start=warmup_date, end=end_date)\n",
    "    \n",
    "    #Calculate SMA and extension at the end of each day\n",
    "    data['SMA'] = data['Close'].rolling(int(sma)).mean()\n",
    "    data['extension'] = (data['Close'] - data['SMA']) / data['SMA']\n",
    "    data['SMA_short_long'] = data['Close'].rolling(int(short_term_sma)).mean() / data['Close'].rolling(int(long_term_sma)).mean()\n",
    "    \n",
    "    #Check the strategy criteria at the end of each day and adjust the position accordingly\n",
    "    data = strat_decision(data, strat, threshold, safety_threshold, short_long_threshold, safety)\n",
    "    \n",
    "    #Get data from first valid day, i.e. first day where NaN due to warm-up doesn't occur\n",
    "    first_valid_day = data['SMA_short_long'].first_valid_index()\n",
    "    \n",
    "    #Calculate returns and statistics\n",
    "    data['returns'] = data['Close'] / data['Close'].shift(1)\n",
    "    #data['returns'] = returns/return_normalization #Normalize the buy&hold returns for warm-up\n",
    "    data['log_returns'] = np.log(data['returns'])\n",
    "    data['strat_returns'] = data['position'].shift(1) * data['returns']\n",
    "    data['strat_log_returns'] = data['position'].shift(1) * data['log_returns']\n",
    "    #Normalize buy&hold returns for warm-up\n",
    "    cum_returns = np.exp(data['log_returns'].cumsum())\n",
    "    cum_returns_normalization = cum_returns.loc[first_valid_day]\n",
    "    data['cum_returns'] = cum_returns/cum_returns_normalization\n",
    "\n",
    "    data['strat_cum_returns'] = np.exp(data['strat_log_returns'].cumsum())\n",
    "    data['peak'] = data['cum_returns'].cummax()\n",
    "    data['strat_peak'] = data['strat_cum_returns'].cummax()    \n",
    "    \n",
    "    return data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStratStats(data, verbose=False, risk_free_rate=0.02):\n",
    "    sma_strat, buy_hold_strat = {}, {}\n",
    "    \n",
    "    #Total Returns\n",
    "    sma_strat['tot_returns'] = np.exp(data['strat_log_returns'].sum()) - 1\n",
    "    buy_hold_strat['tot_returns'] = np.exp(data['log_returns'].sum()) - 1\n",
    "\n",
    "    #Mean Annual Returns\n",
    "    sma_strat['annual_returns'] = np.exp(data['strat_log_returns'].mean()*252) - 1\n",
    "    buy_hold_strat['annual_returns'] = np.exp(data['log_returns'].mean()*252) - 1\n",
    "\n",
    "    #Annual Volatility\n",
    "    sma_strat['annual_volatility'] = data['strat_log_returns'].std() * np.sqrt(252)\n",
    "    buy_hold_strat['annual_volatility'] = data['log_returns'].std() * np.sqrt(252)\n",
    "    \n",
    "    #Sharpe Ratio\n",
    "    #sma_strat['sharpe_ratio'] = (sma_strat['annual_returns'] - risk_free_rate) / sma_strat['annual_volatility']\n",
    "    #buy_hold_strat['sharpe_ratio'] = (buy_hold_strat['annual_returns'] - risk_free_rate) / buy_hold_strat['annual_volatility']\n",
    "    \n",
    "    #Max Drawdown\n",
    "    _strat_dd = data['strat_peak'] - data['strat_cum_returns']\n",
    "    _buy_hold_dd = data['peak'] - data['cum_returns']\n",
    "    sma_strat['max_drawdown'] = _strat_dd.max()\n",
    "    buy_hold_strat['max_drawdown'] = _buy_hold_dd.max()\n",
    "    \n",
    "    try:\n",
    "        #Error in gridsearch occurs somewhere in this block\n",
    "        #Max Drawdown Duration\n",
    "        strat_dd = _strat_dd[_strat_dd==0]\n",
    "        strat_dd_diff = strat_dd.index[1:] - strat_dd.index[:-1]\n",
    "        strat_dd_days = strat_dd_diff.map(lambda x: x.days).values\n",
    "        strat_dd_days = np.hstack([strat_dd_days, (_strat_dd.index[-1] - strat_dd.index[-1]).days])\n",
    "\n",
    "        sma_strat['max_drawdown_duration'] = strat_dd_days.max()\n",
    "    except:\n",
    "        if verbose:\n",
    "            print('IndexError occured due to no drawdown occurences in strategy backtest')\n",
    "        sma_strat['max_drawdown_duration'] = 0.0\n",
    "        #probably have same error of no drawdown occurence, and need to set sma_strat['max_drawdown_duration'] = 0.0\n",
    "\n",
    "    try:\n",
    "        buy_hold_dd = _buy_hold_dd[_buy_hold_dd==0]\n",
    "        buy_hold_dd_diff = buy_hold_dd.index[1:] - buy_hold_dd.index[:-1]\n",
    "        buy_hold_dd_days = buy_hold_dd_diff.map(lambda x: x.days).values\n",
    "        buy_hold_dd_days = np.hstack([buy_hold_dd_days, (_buy_hold_dd.index[-1] - buy_hold_dd.index[-1]).days])\n",
    "        #Calculate max drawdown duration as largest difference between reaching a peak value and then coming back to that value after falling\n",
    "        buy_hold_strat['max_drawdown_duration'] = buy_hold_dd_days.max()\n",
    "    except IndexError:\n",
    "        if verbose:\n",
    "            print('IndexError occured due to no drawdown occurences in buy&hold backtest')\n",
    "        buy_hold_strat['max_drawdown_duration'] = 0.0\n",
    "    \n",
    "    stats_dict = {'strat_stats': sma_strat, 'base_stats': buy_hold_strat}\n",
    "\n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_DrawdownStats(data): \n",
    "    \"\"\"\n",
    "    Calculate the max drawdown and max drawdown duration of a portfolio \n",
    "    given the cumulative returns df \n",
    "    \"\"\"\n",
    "    \n",
    "    sma_strat, buy_hold_strat = {}, {}\n",
    "    \n",
    "    #Get the peak values\n",
    "    data['peak'] = data['cum_returns'].cummax()\n",
    "    data['strat_peak'] = data['strat_cum_returns'].cummax()\n",
    "    \n",
    "    #Max Drawdown\n",
    "    _strat_dd = data['strat_peak'] - data['strat_cum_returns']\n",
    "    _buy_hold_dd = data['peak'] - data['cum_returns']\n",
    "    sma_strat['max_drawdown'] = _strat_dd.max()\n",
    "    buy_hold_strat['max_drawdown'] = _buy_hold_dd.max()\n",
    "    \n",
    "    #Max Drawdown Duration\n",
    "    strat_dd = _strat_dd[_strat_dd==0]\n",
    "    strat_dd_diff = strat_dd.index[1:] - strat_dd.index[:-1]\n",
    "    strat_dd_days = strat_dd_diff.map(lambda x: x.days).values\n",
    "    strat_dd_days = np.hstack([strat_dd_days, (_strat_dd.index[-1] - strat_dd.index[-1]).days])\n",
    "    \n",
    "    sma_strat['max_drawdown_duration'] = strat_dd_days.max()\n",
    "    \n",
    "    try:\n",
    "        buy_hold_dd = _buy_hold_dd[_buy_hold_dd==0]\n",
    "        buy_hold_dd_diff = buy_hold_dd.index[1:] - buy_hold_dd.index[:-1]\n",
    "        buy_hold_dd_days = buy_hold_dd_diff.map(lambda x: x.days).values\n",
    "        buy_hold_dd_days = np.hstack([buy_hold_dd_days, (_buy_hold_dd.index[-1] - buy_hold_dd.index[-1]).days])\n",
    "        #Calculate max drawdown duration as largest difference between reaching a peak value and then coming back to that value after falling\n",
    "        buy_hold_strat['max_drawdown_duration'] = buy_hold_dd_days.max()\n",
    "    except IndexError:\n",
    "        if verbose:\n",
    "            print('IndexError occured due to no drawdown occurences')\n",
    "        buy_hold_strat['max_drawdown_duration'] = 0.0\n",
    "    \n",
    "    dd_dict = {'strat_stats': sma_strat, 'base_stats': buy_hold_strat}\n",
    "    \n",
    "    return dd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPortfolioStrat(strat_settings):\n",
    "    \"\"\"\n",
    "    Take a strategy function and apply it to a list of tickers and current positions.\n",
    "    Return the decisions in a dataframe.\n",
    "    \n",
    "    Should eventually package all of the strategy settings into a strat_settings array variable to make this \n",
    "    easier to change, more readable, and robust enough to use different strat_func's with non-identical inputs. \n",
    "    Will pack the settings before using applyPortfolioStrat and then unpack inside of strat_func.\n",
    "    \n",
    "    applyPortfolioStrat(strat_func, strat_settings, tickers, current_positions)\n",
    "    SMAMeanReversion_strat(strat_settings, ticker, current_position)\n",
    "    \n",
    "    strat_func, tickers, current_positions, SMA, threshold, safety=False, safety_threshold=0.25, short_term_sma=30, long_term_sma=90, short_long_threshold=0.05\n",
    "    \"\"\"\n",
    "    #Unpack strat_settings\n",
    "    [strat_func, tickers, current_positions, SMA, threshold, safety, safety_threshold, short_term_sma, long_term_sma, short_long_threshold, tp_threshold] = strat_settings\n",
    "    \n",
    "    #Apply the strategy to each ticker in the portfolio and append the decisions\n",
    "    strat_setting_0 = [tickers[0],SMA,threshold,current_positions[0],safety,safety_threshold,short_term_sma,long_term_sma,short_long_threshold,tp_threshold]\n",
    "    decisions, _ = strat_func(strat_setting_0)\n",
    "    if len(tickers)>1:\n",
    "        for i in range(1,len(tickers)):\n",
    "            strat_setting_i = [tickers[i],SMA,threshold,current_positions[i],safety,safety_threshold,short_term_sma,long_term_sma,short_long_threshold,tp_threshold]\n",
    "            decision, _ = strat_func(strat_setting_i)\n",
    "            decisions = decisions.append(decision)\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some styling to the decisions dataframe output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_code_ext(value):\n",
    "    if value<0:\n",
    "        color='green'\n",
    "    elif value>0:\n",
    "        color='red'\n",
    "    else:\n",
    "        color='black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "def color_code_sl(value):\n",
    "    if value>1:\n",
    "        color='red'\n",
    "    elif value<1:\n",
    "        color='green'\n",
    "    else:\n",
    "        color='black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "def color_code_m(value):\n",
    "    if value=='Buy':\n",
    "        color='green'\n",
    "    elif value=='Sell':\n",
    "        color='red'\n",
    "    else:\n",
    "        color='blue'\n",
    "    return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_dashboard(decisions):\n",
    "    \"\"\"\n",
    "    Print out a dashboard displaying the strategy decisions and statistics for each ticker in a portfolio\n",
    "    \"\"\"\n",
    "    decisions_dash = decisions.reset_index(drop=True).style.format(precision=3).applymap(color_code_ext, subset=['extension']).applymap(color_code_sl, subset=['short_long ratio']).applymap(color_code_m, subset=['movement'])\n",
    "    display(decisions_dash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that applies the backtest to a portfolio containing a list of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolioBacktest(strat_settings):\n",
    "        \"\"\"\n",
    "        Apply the backtest function to every ticker in a list. Create a dictionary containing\n",
    "        the running cumulative returns data of each ticker, and a dictionary containing the \n",
    "        statistical performance of each ticker.\n",
    "        \n",
    "        Need to handle the errors caused by:\n",
    "            - stock didn't exist at the beginning of given time frame (caused by max drawdown length)\n",
    "            - divide by zero error (caused by sharpe ratio)\n",
    "            - index -1 out of range for array of size 0 (caused by max drawdown length)\n",
    "            Update: all 3 of these errors seem to be fixed by removing sharpe ratio and adding a try-except for \n",
    "            stocks which don't experience buy&hold drawdown in the post-burn-in period. \n",
    "        \"\"\"\n",
    "        #tickers, strat, SMA, threshold, safety=True, safety_threshold=0.25, short_term_sma=30, long_term_sma=90, short_long_threshold=0.05, start_date='2000-01-01',end_date='2020-12-31', verbose=False\n",
    "        #Unpack args\n",
    "        [tickers, strat, SMA, threshold, safety, safety_threshold, short_term_sma, long_term_sma, short_long_threshold, start_date, end_date, verbose] = strat_settings\n",
    "        \n",
    "        #Store the returns and stats of each ticker in the portfolio\n",
    "        portfolio_returns = {}\n",
    "        portfolio_stats = {}\n",
    "        for i in range(0,len(tickers)):\n",
    "            if verbose:\n",
    "                print('Backtesting', tickers[i])\n",
    "            #Get the backtest returns and stats for ticker i\n",
    "            strat_settings_i = [tickers[i], strat, SMA, threshold, safety, safety_threshold, short_term_sma, long_term_sma, short_long_threshold, start_date,end_date]\n",
    "            data_df = stratBacktest(strat_settings_i)\n",
    "            #Get data from first valid day, i.e. first day where NaN due to warm-up doesn't occur\n",
    "            first_valid_day = data_df['SMA_short_long'].first_valid_index()\n",
    "            if i==0:\n",
    "                start_day = first_valid_day\n",
    "            if i>0:\n",
    "                #Check whether this is the latest first_valid_day value so far; If so, update it\n",
    "                if first_valid_day.to_pydatetime()>start_day.to_pydatetime():\n",
    "                    start_day = first_valid_day\n",
    "            \n",
    "        for i in range(0,len(tickers)):\n",
    "            #Clip the data so that we evaluate performance from the first day that the strategy is warmed up and starts making decisions\n",
    "            data_clipped = data_df[start_day:]\n",
    "            stats_df = pd.DataFrame(getStratStats(data_clipped, verbose)).round(3)\n",
    "            returns_df = data_clipped[['cum_returns','strat_cum_returns']]\n",
    "\n",
    "            #Store the returns and stats of the ticker\n",
    "            portfolio_returns[tickers[i]] = returns_df\n",
    "            portfolio_stats[tickers[i]] = stats_df\n",
    "        \n",
    "        #Sum the returns and stats across the portfolio\n",
    "        portfolio_sum_returns, portfolio_sum_stats = sum_metrics(tickers, portfolio_returns, portfolio_stats)\n",
    "        \n",
    "        return portfolio_sum_returns, portfolio_sum_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to take the portfolio_returns dictionary and sum the overall returns of the portfolio, then plot strat vs buy and hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_metrics(tickers, portfolio_returns, portfolio_stats):\n",
    "    \n",
    "    #Get the returns and stats from the first ticker\n",
    "    portfolio_sum_returns = portfolio_returns[tickers[0]]\n",
    "    portfolio_sum_stats = portfolio_stats[tickers[0]]\n",
    "    #For each remaining ticker, add the returns and stats to the portfolio total sum\n",
    "    if len(tickers)>1:\n",
    "        for i in range(1,len(tickers)):\n",
    "            \"\"\"\n",
    "            #Add the returns to the portfolio sum, handling differing start dates nan error\n",
    "            #This fix caused another problem since a jump in cum_return occurs when a new ticker is introduced. Could\n",
    "            #fix this with a normalization that divides the return by the total number of tickers active on a daily \n",
    "            #basis instead of the total number of tickers given.\n",
    "            #For now I'll just stick with the start time being restricted by the newest ticker since I have more confidence in the results\n",
    "            if portfolio_sum_returns.first_valid_index() == portfolio_returns[tickers[i]].first_valid_index():\n",
    "                print(portfolio_sum_returns.first_valid_index())\n",
    "                print(portfolio_returns[tickers[i]].first_valid_index())\n",
    "                portfolio_sum_returns = portfolio_sum_returns + portfolio_returns[tickers[i]]\n",
    "            else:\n",
    "                print(portfolio_sum_returns.first_valid_index())\n",
    "                print(portfolio_returns[tickers[i]].first_valid_index())\n",
    "                #Leave values unchanged for rows where tickers[i] has nan values\n",
    "                start_row = portfolio_sum_returns.first_valid_index()\n",
    "                end_row = portfolio_returns[tickers[i]].first_valid_index()\n",
    "                portfolio_sum_returns.loc[start_row:end_row,'cum_returns'][:-1] = portfolio_sum_returns.loc[start_row:end_row,'cum_returns'][:-1]\n",
    "                portfolio_sum_returns.loc[start_row:end_row,'strat_cum_returns'][:-1] = portfolio_sum_returns.loc[start_row:end_row,'strat_cum_returns'][:-1]\n",
    "                #Add the returns for rows where tickers[i] has real values\n",
    "                print(portfolio_returns[tickers[i]]['cum_returns'])\n",
    "                portfolio_sum_returns.loc[end_row:,'cum_returns'] = portfolio_sum_returns.loc[end_row:,'cum_returns'] + portfolio_returns[tickers[i]]['cum_returns']\n",
    "            \"\"\"\n",
    "            portfolio_sum_returns = portfolio_sum_returns + portfolio_returns[tickers[i]]\n",
    "            #Add the stats to the portfolio sum    \n",
    "            portfolio_sum_stats = portfolio_sum_stats + portfolio_stats[tickers[i]]\n",
    "    #Re-normalize the portfolio total sum\n",
    "    portfolio_sum_returns = portfolio_sum_returns/len(tickers)\n",
    "    #Re-normalize the portfolio return & volatility stats\n",
    "    portfolio_sum_stats.iloc[0:3] = portfolio_sum_stats.iloc[0:3]/len(tickers)\n",
    "    #Calculate the portfolio drawdown stats\n",
    "    dd_stats = portfolio_DrawdownStats(portfolio_sum_returns)\n",
    "    portfolio_sum_stats.iloc[3][0] = dd_stats['strat_stats']['max_drawdown']\n",
    "    portfolio_sum_stats.iloc[4][0] = dd_stats['strat_stats']['max_drawdown_duration']\n",
    "    portfolio_sum_stats.iloc[3][1] = dd_stats['base_stats']['max_drawdown']\n",
    "    portfolio_sum_stats.iloc[4][1] = dd_stats['base_stats']['max_drawdown_duration']\n",
    "    \n",
    "    return portfolio_sum_returns, portfolio_sum_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_portfolio_backtest(portfolio_returns):\n",
    "    \"\"\"\n",
    "    There is an issue here where MRT returns only start after the averaging burn-in, while buy&hold starts \n",
    "    immediately, so the buy&hold returns are given a head start. This should be resolved when I add \n",
    "    a pre-burn-in period in stratBacktest.\n",
    "    \"\"\"\n",
    "    #Normalize returns to the first valid day\n",
    "    first_valid_day = portfolio_returns.first_valid_index()\n",
    "    returns_normalized = portfolio_returns/portfolio_returns.loc[first_valid_day]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.plot(returns_normalized['strat_cum_returns'], label='Mean Reversion Strategy with Safety and Ensemble')\n",
    "    ax.plot(returns_normalized['cum_returns'], label='Buy and Hold Strategy')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Returns (%)')\n",
    "    ax.set_title('Cumulative Returns for Mean Reversion and Buy and Hold Strategies')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that applies the portfolio backtest for each point on a grid of hyperparameters and returns a plot of each of the major strategy metrics (annual returns, volatility, max drawdown). This will probably be a corner plot where I can see the effect of each parameter and pick the desired min/max location.\n",
    "\n",
    "Could start with just annual returns to avoid multi-objective optimization. Seems like a good metric to use.\n",
    "\n",
    "Note: sharpe ratio and max_drawdown_duration both cause errors, and probably aren't the most relevant metrics anyways, so I won't use them.\n",
    "\n",
    "Possibly use MCMC or another optimization algorithm for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_return_diff(portfolio_stats):\n",
    "    #Calculate annual return difference of the portfolio\n",
    "    strat_annual_returns = portfolio_stats['strat_stats']['annual_returns']\n",
    "    base_annual_returns = portfolio_stats['base_stats']['annual_returns']\n",
    "    annual_return_diff = strat_annual_returns - base_annual_returns\n",
    "    return annual_return_diff\n",
    "\n",
    "def annual_return_ratio(portfolio_stats):\n",
    "    #Calculate annual return difference of the portfolio\n",
    "    strat_annual_returns = portfolio_stats['strat_stats']['annual_returns']\n",
    "    base_annual_returns = portfolio_stats['base_stats']['annual_returns']\n",
    "    annual_return_ratio = strat_annual_returns/base_annual_returns\n",
    "    return annual_return_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_gridsearch(tickers, N):\n",
    "    \"\"\"\n",
    "    Perform a gridsearch to find the hyperparameters that optimize strategy performance\n",
    "    \n",
    "    tickers - array of stocks/cryptos to consider in our portfolio\n",
    "    N - number of gridpoints to search in each hyperparameter\n",
    "    \"\"\"\n",
    "\n",
    "    #Set strategy and dates\n",
    "    start_date = '2018-05-01'\n",
    "    end_date = '2021-10-17'\n",
    "    strat='SMA_MR'\n",
    "    #Keep these set for now. Might try comparing with & without the safety \n",
    "    verbose = False\n",
    "    safety = True\n",
    "    \n",
    "    #Hyperparam bounds\n",
    "    SMAb = [2,200]\n",
    "    thresholdb = [0.01,1.0]\n",
    "    safety_thresholdb = [0.01,1.0]\n",
    "    short_term_smab = [2,90]\n",
    "    long_term_smab = [10,200]\n",
    "    short_long_thresholdb = [0.01,1.0]\n",
    "    \n",
    "    #Hyperparam vectors\n",
    "    SMAv = np.linspace(SMAb[0],SMAb[1],N)\n",
    "    thresholdv = np.linspace(thresholdb[0],thresholdb[1],N)\n",
    "    safety_thresholdv = np.linspace(safety_thresholdb[0],safety_thresholdb[1],N)\n",
    "    short_term_smav = np.linspace(short_term_smab[0],short_term_smab[1],N)\n",
    "    long_term_smav = np.linspace(long_term_smab[0],long_term_smab[1],N)\n",
    "    short_long_thresholdv = np.linspace(short_long_thresholdb[0],short_long_thresholdb[1],N)\n",
    "    \n",
    "    #Save the parameter vectors\n",
    "    param_vecs = [SMAv, thresholdv, safety_thresholdv, short_term_smav, long_term_smav, short_long_thresholdv]\n",
    "    #cols = ['SMA', 'threshold', 'safety_threshold', 'short_term_sma', 'long_term_sma', 'short_long_threshold']\n",
    "    #params_df = pd.DataFrame(vecs, columns=cols) #ValueError: 6 columns passed, passed data had 3 columns\n",
    "    \n",
    "    #Initialize storage for statistic evaluated on grid\n",
    "    stat_grid = np.empty([N, N, N, N, N, N])\n",
    "    \n",
    "    #Not sure if I can eventually vectorize this?\n",
    "    #SMAg, thresholdg, safety_thresholdg, short_term_smag, long_term_smag, short_long_thresholdg = np.meshgrid(SMAv, thresholdv, safety_thresholdv, short_term_smav, long_term_smav, short_long_thresholdv)\n",
    "    \n",
    "    npts = N**6\n",
    "    print('Performing hyperparameter gridsearch. Grid size=',npts)\n",
    "    count = 0\n",
    "    for i1 in range(0,N):\n",
    "        for i2 in range(0,N):\n",
    "            for i3 in range(0,N):\n",
    "                print(count,' of ',npts,' gridpoints')\n",
    "                for i4 in range(0,N):\n",
    "                    for i5 in range(0,N):\n",
    "                        for i6 in range(0,N):\n",
    "                            count = count+1\n",
    "                            #Get the hyperparams for this gridpoint\n",
    "                            SMA = SMAv[i1]\n",
    "                            threshold = thresholdv[i2]\n",
    "                            safety_threshold = safety_thresholdv[i3]\n",
    "                            short_term_sma = short_term_smav[i4]\n",
    "                            long_term_sma = long_term_smav[i5]\n",
    "                            short_long_threshold = short_long_thresholdv[i6]\n",
    "                            #Check that this gridpoint meets our constraints. If yes, evaluate the model.\n",
    "                            \"\"\"\n",
    "                            Constraints: \n",
    "                            safety_threshold > threshold\n",
    "                            long_term_sma > short_term_sma\n",
    "                            \"\"\"\n",
    "                            if (safety_threshold>threshold) and (long_term_sma>short_term_sma):\n",
    "                                strat_settings = [tickers, strat, SMA, threshold, safety, safety_threshold, short_term_sma, long_term_sma, short_long_threshold, start_date, end_date, verbose]\n",
    "                                \n",
    "                                #Run the backtest on the entire portfolio\n",
    "                                portfolio_returns, portfolio_stats = portfolioBacktest(strat_settings)\n",
    "                                #Calculate annual return ratio of the portfolio\n",
    "                                strat_annual_returns = portfolio_stats['strat_stats']['annual_returns']\n",
    "                                base_annual_returns = portfolio_stats['base_stats']['annual_returns']\n",
    "                                #annual_return_ratio = strat_annual_returns/base_annual_returns\n",
    "                                annual_return = strat_annual_returns - base_annual_returns\n",
    "                                \n",
    "                                #Store the result\n",
    "                                stat_grid[i1,i2,i3,i4,i5,i6] = annual_return\n",
    "                                \n",
    "    print('Gridsearch completed')\n",
    "    return stat_grid, param_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stat_grid(stat_grid, min_val=1e-5, max_val=1e2, neg_val=5):\n",
    "    \"\"\"\n",
    "    Remove unreasonably large, small, and negative values from the gridsearch results\n",
    "    \"\"\"\n",
    "    stat_grid = np.where(stat_grid > max_val, 0, stat_grid) #Drop unreasonably large values\n",
    "    stat_grid = np.where(np.abs(stat_grid) < min_val, 0, stat_grid) #Drop unrealistically small values\n",
    "    stat_grid = np.where(stat_grid < -neg_val, 0, stat_grid) #Drop negative values below a certain unreasonable cutoff\n",
    "    #Also should remove nan and replace with 0\n",
    "    \n",
    "    return stat_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gridsearch(param_vecs, stat_grid, N):\n",
    "    \"\"\"\n",
    "    Save the results of a gridsearch to two CSV files\n",
    "    \"\"\"\n",
    "    print('Saving Gridsearch Results...')\n",
    "    \n",
    "    #Reshape stat_grid to vector\n",
    "    npts = N**6\n",
    "    stat_vec = np.reshape(stat_grid, npts)\n",
    "\n",
    "    #Save parameter vectors to csv\n",
    "    param_name = 'GridsearchData/param_vecs_N{}.csv'.format(N)\n",
    "    np.savetxt(param_name, param_vecs, delimiter =\", \", fmt ='% s')\n",
    "    #Save gridsearch output statistic vector to csv, with a header giving the array length so we can reshape it when loading it back\n",
    "    head = str(N)\n",
    "    stat_name = 'GridsearchData/stat_vec_N{}.csv'.format(N)\n",
    "    np.savetxt(stat_name, stat_vec, delimiter =\", \", header=head, fmt ='% s')\n",
    "    print('Results Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gridsearch(N):\n",
    "    \"\"\"\n",
    "    Load the results of a gridsearch from two CSV files\n",
    "    \"\"\"\n",
    "    #Load parameter vectors\n",
    "    param_name = 'GridsearchData/param_vecs_N{}.csv'.format(N)\n",
    "    param_vecs = np.loadtxt(param_name, delimiter =\", \") #Need to check if this is the right usage\n",
    "    #Load output statistic vector\n",
    "    stat_name = 'GridsearchData/stat_vec_N{}.csv'.format(N)\n",
    "    stat_vec = np.loadtxt(stat_name, delimiter =\", \")\n",
    "    #Recover original 6D stat_grid\n",
    "    stat_grid = np.reshape(stat_vec, [N, N, N, N, N, N])\n",
    "    \n",
    "    return param_vecs, stat_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_3d_nparray(filename, stat_grid):\n",
    "    # Write the array to disk\n",
    "    with open(filename, 'w') as outfile:\n",
    "        # I'm writing a header here just for the sake of readability\n",
    "        # Any line starting with \"#\" will be ignored by numpy.loadtxt\n",
    "        outfile.write('# Array shape: {0}\\n'.format(stat_grid.shape))\n",
    "\n",
    "        # Iterating through a ndimensional array produces slices along\n",
    "        # the last axis. This is equivalent to data[i,:,:] in this case\n",
    "        for data_slice in stat_grid:\n",
    "\n",
    "            # The formatting string indicates that I'm writing out\n",
    "            # the values in left-justified columns 7 characters in width\n",
    "            # with 2 decimal places.  \n",
    "            np.savetxt(outfile, data_slice) #, fmt='%-7.2f'\n",
    "\n",
    "            # Writing out a break to indicate different slices...\n",
    "            outfile.write('# New slice\\n')\n",
    "        print(filename,'saved')\n",
    "        \n",
    "def load_3d_nparray(stat_name, N):\n",
    "    # Read the array from disk\n",
    "    data = np.loadtxt(stat_name)\n",
    "    # Convert back to original 3D array shape\n",
    "    data = data.reshape((N,N,N))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gridsearch_results(stat_grid, param_vecs, N):\n",
    "    cols = ['SMA', 'threshold', 'safety_threshold', 'short_term_sma', 'long_term_sma', 'short_long_threshold']\n",
    "    arr = np.array([0,1,2,3,4,5]) #List of dimensions\n",
    "    stat_vecs = np.empty([6,N])\n",
    "\n",
    "    for i in range(0,6):\n",
    "        arr = arr[arr != i] #Specify which dimension to drop leave out of the averaging\n",
    "        avg=np.apply_over_axes(np.nanmean, stat_grid, arr) #Average over all axes except the specified axis\n",
    "        #Collapse extra dimensions\n",
    "        if i==0:\n",
    "            avg_flat = avg[:,0,0,0,0,0]\n",
    "        if i==1:\n",
    "            avg_flat = avg[0,:,0,0,0,0]\n",
    "        if i==2:\n",
    "            avg_flat = avg[0,0,:,0,0,0]\n",
    "        if i==3:\n",
    "            avg_flat = avg[0,0,0,:,0,0]\n",
    "        if i==4:\n",
    "            avg_flat = avg[0,0,0,0,:,0]\n",
    "        if i==5:\n",
    "            avg_flat = avg[0,0,0,0,0,:]\n",
    "        stat_vecs[i,:] = avg_flat\n",
    "\n",
    "        #Plot the averaged results\n",
    "        plt.figure()\n",
    "        plt.plot(param_vecs[i], stat_vecs[i],'o')\n",
    "        plt.xlabel(cols[i])\n",
    "        plt.ylabel('Annual Return Difference (Strat - B&H)')\n",
    "    \n",
    "    return stat_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPortfolioToFeed(tickers, cerebro, start_date, end_date):\n",
    "    \n",
    "    for t in tickers:\n",
    "        data = bt.feeds.PandasData(dataname=yf.download(t, start_date, end_date))\n",
    "        #data.plotinfo.plotmaster = data\n",
    "        cerebro.adddata(data, name = t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
